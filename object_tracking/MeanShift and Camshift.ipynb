{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79a018ea-51a3-4738-be1c-2f7f7ae7c87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73343244-59dc-4f24-a37c-ef1626aac71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[212 234 234 234]\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "ret, frame = cap.read()\n",
    "\n",
    "#Set the initial tracking window--> face tracking\n",
    "\"\"\" To achieve this we are doing the following:\n",
    "1. Object detection in the very first frame,to grab the face location\n",
    "2. After the face is detected, we are going to treat it as a bunch of pixels, and then apply mean shift tracking on it.\n",
    "We are just tracking the face at the begining, and then telling the mean shift tracking algorithm to track that particular set.\"\"\"\n",
    "\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "face_rects = face_cascade.detectMultiScale(frame)\n",
    "print(face_rects[0])\n",
    "\"\"\" face_rects: returns a list of numpy arrays when it is detecting a face.\"\"\"\n",
    "(face_x,face_y,w,h)= tuple(face_rects[0])\n",
    "\n",
    "tracking_window =  (face_x, face_y, w,h)\n",
    "\n",
    "roi = frame[face_y: face_y+h, face_x: face_x+w]\n",
    "hsv = cv2.cvtColor(roi,cv2.COLOR_BGR2HSV)\n",
    "roi_hist = cv2.calcHist([hsv,roi],[0],None,[180],[0,180])\n",
    "cv2.normalize(roi_hist,roi_hist,0,255, cv2.NORM_MINMAX)\n",
    "\n",
    "term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10,1)\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret == True:\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        dst = cv2. calcBackProject([hsv],[0], roi_hist, [0,180],1)\n",
    "\n",
    "        ret, tracking_window = cv2.meanShift(dst,tracking_window,term_crit)\n",
    "\n",
    "        x, y, w,h = tracking_window\n",
    "        img2 = cv2.rectangle(frame, (x,y), (x+w, y+h),(0,0,255),5)\n",
    "        cv2.imshow('img',img2)\n",
    "        k = cv2.waitKey(1) & 0xFF\n",
    "        if k == 27:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab929c0-765e-4574-92e4-c2796e9a81ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126d0b89-af51-44e5-a152-cabed8a5aa3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c2fcd11-d002-4e22-aecd-2d7309fa7510",
   "metadata": {},
   "source": [
    "#Cam shift Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73e8cfce-784d-4f57-94bb-bdd51a342029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[357 232  52  52]\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "ret, frame = cap.read()\n",
    "\n",
    "#Set the initial tracking window--> face tracking\n",
    "\"\"\" To achieve this we are doing the following:\n",
    "1. Object detection in the very first frame,to grab the face location\n",
    "2. After the face is detected, we are going to treat it as a bunch of pixels, and then apply mean shift tracking on it.\n",
    "We are just tracking the face at the begining, and then telling the mean shift tracking algorithm to track that particular set.\"\"\"\n",
    "\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "face_rects = face_cascade.detectMultiScale(frame)\n",
    "print(face_rects[0])\n",
    "\"\"\" face_rects: returns a list of numpy arrays when it is detecting a face.\"\"\"\n",
    "(face_x,face_y,w,h)= tuple(face_rects[0])\n",
    "\n",
    "tracking_window =  (face_x, face_y, w,h)\n",
    "\n",
    "roi = frame[face_y: face_y+h, face_x: face_x+w]\n",
    "hsv = cv2.cvtColor(roi,cv2.COLOR_BGR2HSV)\n",
    "roi_hist = cv2.calcHist([hsv,roi],[0],None,[180],[0,180])\n",
    "cv2.normalize(roi_hist,roi_hist,0,255, cv2.NORM_MINMAX)\n",
    "\n",
    "term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10,1)\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret == True:\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        dst = cv2. calcBackProject([hsv],[0], roi_hist, [0,180],1)\n",
    "\n",
    "        ret, tracking_window = cv2.CamShift(dst,tracking_window,term_crit)\n",
    "        pts = cv2.boxPoints(ret)\n",
    "        pts = pts.astype(int)\n",
    "        img2 = cv2.polylines(frame, [pts], True, (0,0,255),5)\n",
    "        \n",
    "        cv2.imshow('img',img2)\n",
    "        k = cv2.waitKey(1) & 0xFF\n",
    "        if k == 27:\n",
    "            break\n",
    "            \n",
    "    else:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a401b92-4e9e-431e-9c59-1974281dd15e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f692dc-9d78-49c1-bcf7-3ed4da275c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
